## 신경세포 모델링: 인공신경망

Artificial Neural Network는 지능이 있는 인간의 신경세포를 모델링하여 인공적으로 지능을 가진 기계를 만들기 위한 것.

- 인간의 신경세포는 20종류가 넘는다.
- 뇌의 대뇌피질에만 $10^12$개에 이르는 뉴런(Neuron)의 연결점인 시냅스(Synapse)존재
- 뇌의 연결배선 (Connectom)

### 생물학적 신경세포

- 수상돌기(dendrite) : input wires
- 축색돌기(axon) : output wire
- 세포체(cell)
- 시냅스(Synapse) : 다른 세포체로부터의 축색돌기 연결
  - 전기신호 (이온에 의한 전기 신호)
  - 일정시간동안 입력된 자극이 세포체내에서 weighted sum이 되어 임계값이상이 되면 뉴런이 활성화되어 축색돌기로 자극이 전달되는 메커니즘.

### McCulloch and Pitts (1943) 모델

- 정신과의사 이자 신경해부학자 (McCulloch), 수학자(Pitts) [1943년]
- A Logical calculus of ideas immanent in nervouse acitity
  - 입력 연결점 (x1, x2, ...xn, x0 바이어스 값)
  - 가중치 (w1, w2, ... wn, w0 바이어스 가중치 포함)
  - 입력함수 (연결점들과 가중치의 합)
  - 활성화함수 (Activation Function)
  - 출력
  - 출력 연결점

- AND, OR, NOT ...
- XOR ?

### Hebb 의 학습규칙 (1949)

- 뉴런간의 연결강도는 학습으로 최적화
- 만일 어떤 신경세포의 활성이 다른 신경세포가 활성화하는데 계속적으로 공헌한다면, 두 신경세포 간의 연결 가중치를 증가해야 한다.


- $w_{ij}^{new} = w_{ij}^{old} + \alpha a_i b_j$
   - $w_{ij}^{new}$ : 신경세포 $i, j$사이의 조절된 후 연결 가중치
   - $w_{ij}^{old}$ : 신경세포 $i, j$사이의 조절되기 전 연결 가중치
   - $\alpha$ : 학습률 ( $ 0 < \alpha <= 1 $)
   - $a_i$ : 신경세포 i의 활성값
   - $b_j$ : 신경세포 j의 활성값

### Rosenblatt 퍼셉트론 (1958)

- The Perceptron: a problabiliistic model for information storage and organization in the brain.
- 신경세포와 유사한 단순 계산 기능을 갖는 입력층과 출력층을 갖는 신경 시스템의 모델명
- LMS(Least Mean Square: 최소자승법) 학습규칙을 바탕으로 복잡한 학습규칙으로 발전

- $ E = \frac{1}{2} Err^2 = \frac{1}{2}(y - h_w(x))^2$

### Minsky, Paper의 퍼셉트론의 한계 (1969)

### Rumelhart, Hinton, Williams (1986)

- 다중 퍼셉트론과 역전파알고리즘(Back propagation)
- 전향 단계: 입력패턴을 제시하고 입력함수와 활성화 함수를 이용하여 출력을 산출하는 단계
- 후향 단계: 목표출력과 실제출력과의 차이를 계산하여 오차를 구하고, 이를 역방향으로 순서대로 연결강도를 갱신하는 단계
- 미리정한 오차값이내에 도달할 때까지 계속

### 패턴인식과 신경망의 구조

- (전방향) 신경망 (Feedbackforward)
- 회귀신경망 (Recurrent)

- 예측형과 분류형
